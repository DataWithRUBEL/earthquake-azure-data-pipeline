

# Retrieve the task value from the previous task (bronze)
bronze_output = dbutils.jobs.taskValues.get(taskKey="Bronze", key="bronze_output")

# Access individual variables
start_date = bronze_output.get("start_date", "")
bronze_adls = bronze_output.get("bronze_adls", "")
silver_adls = bronze_output.get("silver_adls", "")

print(f"Start Date: {start_date}, Bronze ADLS: {bronze_adls}")
     

from pyspark.sql.functions import col, isnull, when
from pyspark.sql.types import TimestampType
from datetime import date, timedelta
     

# Load the JSON data into a Spark DataFrame
df = spark.read.option("multiline", "true").json(f"{bronze_adls}{start_date}_earthquake_data.json")
     

df.head()
     
Row(geometry=Row(coordinates=[39.9762, 9.0693, 9.256], type='Point'), id='us6000pihl', properties=Row(alert=None, cdi=None, code='6000pihl', detail='https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pihl&format=geojson', dmin=3.736, felt=None, gap=146.0, ids=',us6000pihl,', mag=4.5, magType='mb', mmi=None, net='us', nst=18, place='19 km NNE of Metahāra, Ethiopia', rms=0.55, sig=312, sources=',us,', status='reviewed', time=1736292406702, title='M 4.5 - 19 km NNE of Metahāra, Ethiopia', tsunami=0, type='earthquake', types=',origin,phase-data,', tz=None, updated=1736294300040, url='https://earthquake.usgs.gov/earthquakes/eventpage/us6000pihl'), type='Feature')

# Reshape earthquake data
df = (
    df
    .select(
        'id',
        col('geometry.coordinates').getItem(0).alias('longitude'),
        col('geometry.coordinates').getItem(1).alias('latitude'),
        col('geometry.coordinates').getItem(2).alias('elevation'),
        col('properties.title').alias('title'),
        col('properties.place').alias('place_description'),
        col('properties.sig').alias('sig'),
        col('properties.mag').alias('mag'),
        col('properties.magType').alias('magType'),
        col('properties.time').alias('time'),
        col('properties.updated').alias('updated')
    )
)
     

df.head()
     
Row(id='us6000pihl', longitude=39.9762, latitude=9.0693, elevation=9.256, title='M 4.5 - 19 km NNE of Metahāra, Ethiopia', place_description='19 km NNE of Metahāra, Ethiopia', sig=312, mag=4.5, magType='mb', time=1736292406702, updated=1736294300040)

# Validate data: Check for missing or null values
df = (
    df
    .withColumn('longitude', when(isnull(col('longitude')), 0).otherwise(col('longitude')))
    .withColumn('latitude', when(isnull(col('latitude')), 0).otherwise(col('latitude')))
    .withColumn('time', when(isnull(col('time')), 0).otherwise(col('time')))
)
     

# Convert 'time' and 'updated' to timestamp from Unix time
df = (
    df
    .withColumn('time', (col('time') / 1000).cast(TimestampType()))
    .withColumn('updated', (col('updated') / 1000).cast(TimestampType()))
)
     

df.head()
     
Row(id='us6000pihl', longitude=39.9762, latitude=9.0693, elevation=9.256, title='M 4.5 - 19 km NNE of Metahāra, Ethiopia', place_description='19 km NNE of Metahāra, Ethiopia', sig=312, mag=4.5, magType='mb', time=datetime.datetime(2025, 1, 7, 23, 26, 46, 702000), updated=datetime.datetime(2025, 1, 7, 23, 58, 20, 40000))

# Save the transformed DataFrame to the Silver container
silver_output_path = f"{silver_adls}earthquake_events_silver/"
     

# Append DataFrame to Silver container in Parquet format
df.write.mode('append').parquet(silver_output_path)
     

dbutils.jobs.taskValues.set(key = "silver_output", value = silver_output_path)
     
